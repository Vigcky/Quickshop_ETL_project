x-airflow-common: &airflow-common
  image: apache/airflow:2.7.3
  environment: &airflow-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:182003@postgres:5432/airflow
    AIRFLOW__CORE__FERNET_KEY: "hMQf7jD7bXbit3qRfjQsUndtgvzFWtGLkpU4AV0HPRo="
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    AIRFLOW__LOGGING__LOGGING_LEVEL: "INFO"
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./out:/opt/airflow/out
    - ./data:/opt/airflow/data
    - ./run_etl.py:/opt/airflow/run_etl.py
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    - postgres

services:
  postgres:
    image: postgres:16
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: 182003
      POSTGRES_DB: quickshop
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  airflow-init:
    <<: *airflow-common
    command: bash -c "airflow db init && airflow users create --username admin --firstname admin --lastname user --role Admin --email admin@local --password admin || true"
    restart: "no"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always
    depends_on:
      - airflow-init

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"
    restart: always
    depends_on:
      - airflow-init
      - airflow-scheduler

  flask_app:
    build: .
    restart: always
    environment:
      - FLASK_APP=app.py
      - FLASK_ENV=development
    ports:
      - "5000:5000"
    volumes:
      - .:/app
      - ./data:/app/data
      - ./out:/app/out
    depends_on:
      - postgres

volumes:
  pgdata:
  airflow_logs:
